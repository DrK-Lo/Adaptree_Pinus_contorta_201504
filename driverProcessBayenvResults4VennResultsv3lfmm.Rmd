---
title: "Outlier and Venn Diagram Results from Pinus contorta at different cutoffs for LFMM"
author: "Katie Lotterhos"
date: "April 28, 2015"
output: html_document
---
Data used here is stored on hulk at /data/seqcap/pine/bwa_pseudo/round2_bams/bayenvResults20150416.  It was transferred to klott@10.122.4.190:/Users/lotterke/Desktop/bayenvResults20150416 to make the markdown files

```{r, echo=FALSE, eval=FALSE}
rmarkdown::render("driverProcessBayenvResults4VennResultsv3lfmm.Rmd")
```

In this analysis, we ran lfmm (Frichot et al 2013) on over 200,000 SNPs from the Pine sequence capture.  We had 22 environmental variables of biological interest.

```{r, echo=FALSE}
### set the wd
setwd("/Users/katie/Desktop/current projects/1-AdaptreeData/2015_POST_FILTERING/pine_src") 
if(!("rmarkdown" %in% installed.packages())) {install.packages("rmarkdown", dependencies=TRUE)}
if(!("limma" %in% installed.packages())) {
  source("http://www.bioconductor.org/biocLite.R")
  biocLite("limma")
  }
if(!("xtable" %in% installed.packages())) {install.packages("xtable", dependencies=TRUE)}
library(rmarkdown)
library(limma)
library(xtable)
### rmarkdown::render("driverProcessBayenvResults4VennResultsv2.Rmd")
````

### Information about this R session
```{r session}
sessionInfo()
```

### The SNP dataset 

Here are the column names in the SNP dataset: (the ones named after the environments contain Bayes Factors from bayenv2 (Gunther and Coop 2013).  "rho" represents Spearman's rho also estimated from Bayenv 2, which indicates the correlation between the reference SNP frequency and the environment.)  For the LFMM output (organized by Simon), columns are named
envvar.z.lfmm.beagle for zscores (note that the abs(Zscore) should be used for calculating outliers) and envvar.q.lffm.beagle for q-values (I would not rely too much on q values).

```{r read in file}
filename <- "../pine_data/bayenv.lfmmbeagle.res"
### read in file with log-BF
  if(!("f2" %in% ls())){
    f2<- read.table(filename, header=TRUE, comment.char="")
  }
  names(f2)

env <- read.table("../pine_data/sprucePineEnvi.clusters", header=TRUE)
env <- env[order(env$G4),]

```


The abs(z-scores) from all environments were pooled to calculate cutoffs for the different quartiles of the z-score distribution.  Here are the cutoffs for those percentiles (calculated by Simon):
```{r BF cutoffs}
### read in file with cutoffs
  cos <- read.table("../pine_data/zscore_cutoffs", header=TRUE)
  cos <- data.frame(-99, cos) #differs from Bayenv script
  names(cos)[1] <- "All"
  cos 
```


#### Now loop through some these cutoffs and summarize the results for environment enrichment:

```{r loop through cutoffs Venn xtables, echo=FALSE, results='asis'}
   colBF <- c()
  colname.lfmm <- as.character(paste(env$enviAbb, ".z.lfmm.beagle", sep=""))

    for (i in 1:22){
      colBF[i] <- which(names(f2)==colname.lfmm[i]) #this line differs from bayenv script
      }
  ### unit test
  if(!identical(names(f2)[colBF],colname.lfmm)){print("Error in matching names"); break}

  colname.lfmm.envi <- sub(".z.lfmm.beagle", "", names(f2)[colBF]) #new line of code to match environments to env

  groupsize <- tapply(env$G4,env$G4, length)
  groupsize2 <- groupsize[2:4]/sum(groupsize[2:4])

  which.cutoffs <- c(1, 4:8)
  envitable <- envitable.perc <- data.frame(env[,1:2])
  LLEtable <- data.frame(Category = c("LAT.lfmm", "LONG.lfmm", "ELEVATION.lfmm"))
  LLEtable.perc <- LLEtable 
  Grouptable <- Grouptable.perc <- data.frame(Category = c("Group 1 (temp)", "Group 2 (precip)", "Group 3 (frost-free)"))
  
  Grouptable.scaled <- Grouptable.scaled.perc <- data.frame(Category = c("Group 1 (temp) scaled", "Group 2 (precip) scaled", "Group 3 (frost-free) scaled"))

### for each cutoff, 
  f3 <- f2

  for (i in which.cutoffs){
    BFcutoff <- round(cos[1,i],3) #keeping notation but we are doing z-scores not BF
    cutoff <- names(cos[i])
  
    
    ### convert bF columns to T/F for outliers
      f3[,colBF] <- abs(f2[,colBF]) > BFcutoff #note use of abs() for z-scores
      #head(f3[,colBF])
      overall.out <- rowSums(f3[,colBF])>0  
     cat("\n")

    
    ### number of outliers in each environment
      numOutliers <-  as.numeric(unlist(colSums(f3[,colBF], na.rm=TRUE)))
      perc.outliers <- numOutliers/sum(numOutliers)
    #print(numOutliers)
      envitable <- data.frame(envitable,numOutliers)
      envitable.perc <- data.frame(envitable.perc, perc.outliers)
      colnames(envitable)[ncol(envitable)] <- paste("numOutliers", cutoff, sep=".")
    colnames(envitable.perc)[ncol(envitable)] <- paste("percOfOutliers", cutoff, sep=".")
    
    ### outliers in lat long elevation
    LLE <- c(sum(f3$LAT.z.lfmm.beagle, na.rm=TRUE), sum(f3$LONG.z.lfmm.beagle, na.rm=TRUE), sum(f3$ELEVATION.z.lfmm.beagle, na.rm=TRUE)) #note appended names here, differes from bayenv script
    LLEtable <- data.frame(LLEtable, LLE)  
    LLEtable.perc <- data.frame(LLEtable.perc,LLE/sum(LLE))
    colnames(LLEtable)[ncol(LLEtable)] <- paste("numOutliers", cutoff, sep=".")
    colnames(LLEtable.perc)[ncol(LLEtable)] <- paste("percOfOutliers", cutoff, sep=".")
    
    ### compute outliers for each cluster (3 columns) 
    ### note the following 3 lines differ from the bayenv script
      G1cols <- colBF[which(colname.lfmm.envi %in% env$enviAbb[env$G4==1])]
      G2cols <- colBF[which(colname.lfmm.envi %in% env$enviAbb[env$G4==2])]
      G3cols <- colBF[which(colname.lfmm.envi %in% env$enviAbb[env$G4==3])]
      ### unit test
       if((length(G1cols) + length(G2cols) + length(G3cols))!=19){print("Error in envi clusters")}
      G1 <- rowSums(f3[,G1cols])>0
      G2 <- rowSums(f3[,G2cols])>0
      G3 <- rowSums(f3[,G3cols])>0
    
      G123 <- c(sum(G1, na.rm=TRUE), sum(G2, na.rm=TRUE), sum(G3, na.rm=TRUE))
      Grouptable <- data.frame(Grouptable, G123) #, G123/sum(G123))
      Grouptable.perc <- data.frame(Grouptable.perc, G123/sum(G123))
      colnames(Grouptable)[ncol(Grouptable)] <- paste("numOutliers", cutoff, sep=".")
      colnames(Grouptable.perc)[ncol(Grouptable)] <- paste("numOutliers", cutoff, sep=".")
      
      G123scaled <- c(round(sum(G1, na.rm=TRUE)/groupsize[2],1),
                      round(sum(G2, na.rm=TRUE)/groupsize[3],1),
                      round(sum(G3, na.rm=TRUE)/groupsize[4],1)
                      )
    Grouptable.scaled <- data.frame(Grouptable.scaled, G123scaled) #, G123scaled/sum(G123scaled))
    Grouptable.scaled.perc <- data.frame(Grouptable.scaled.perc, G123scaled/sum(G123scaled))
      colnames(Grouptable.scaled)[ncol(Grouptable.scaled)] <- paste("numOutliers", cutoff, sep=".")
      colnames(Grouptable.scaled.perc)[ncol(Grouptable.scaled)] <- paste("percOfOutliers", cutoff, sep=".")
      
    
    if (i > 5){
       f3b <- data.frame(f3, G1, G2, G3, overall.out)
      
      #write.table(f3, paste(filename,"gt", names(cos[i]), sep=""))
    
      ### Venn diagram for Lat/Long/Elevation
      c1 <- which(names(f3b) %in% c("LAT.z.lfmm.beagle", "LONG.z.lfmm.beagle", "ELEVATION.z.lfmm.beagle"))
      TF.LLE <- f3b[,c1]
      counts.LLE <- vennCounts(TF.LLE)
      perc.LLE <- counts.LLE
      perc.LLE[1,4] <- 0
      perc.LLE[,4] <- round(perc.LLE[,4]/sum(perc.LLE[,4])*100,1)
      
      ### Venn diagram for G1/G2/G3
      c2 <- names(f3b) %in% c("G1", "G2", "G3")
      TF.Gs <- f3b[,c2]
      counts.Gs <- vennCounts(TF.Gs)
      perc.Gs <- counts.Gs
      perc.Gs[1,4] <- 0
      perc.Gs[,4] <- round(perc.Gs[,4]/sum(perc.Gs[,4])*100,1)
      
    cat(paste ("### Results for", cutoff, "percentile, which corresponds to a abs(z) >", BFcutoff, "..."))
    cat("\n")
      cat(paste("#### Total number of outliers (loci with abs(z) above threshold in any one environment):", sum(overall.out, na.rm=TRUE)), "\n")
     cat("#### Venn diagrams of overlap among variables.  Raw counts on left column, percentages on right column:", "\n", "Note that the number in the bottom right corner of the Venn represents the number of SNPs that do not fit into any category and can be ignored.",  "\n")
       cat("\n")
    par(mfrow=c(2,2), mar=c(0,0,2,1), oma=c(0,0,0,0), cex=0.8)
      vennDiagram(counts.LLE, main = paste(cutoff, "Counts, abs(z) >", BFcutoff), cex=rep(0.7,3))
      vennDiagram(perc.LLE, main = paste(cutoff, " Percents, abs(z) >", BFcutoff), cex=rep(0.7,3))
      vennDiagram(counts.Gs, main = paste("Unscaled", cutoff, " Counts, abs(z) >", BFcutoff),cex=rep(0.7,3))
      vennDiagram(perc.Gs, main = paste("Unscaled", cutoff, " Percents, abs(z) >", BFcutoff),cex=rep(0.7,3))
    }
cat("\n")
      
  }# end loop

cat("\n") 
cat("### Number of outliers based on different cutoffs")
      ### output number of outliers for each environment
      cat("\n")      
      cat(paste ("#### The number of outliers in each environmental variable",  "\n"))
      envitable[,3:ncol(envitable)] <- round(envitable[,3:ncol(envitable)],0)
      print(xtable(envitable), type="html", digits=0)
      #print(xtable(envitable.perc), type="html")
      
      cat("\n")
      cat(paste ("#### The number of outliers for just Lat, Long, and Elevation", "\n"))
      print(xtable(LLEtable), type="html")
      #print(xtable(LLEtable.perc), type="html")
      
      cat("\n")
      cat(paste ("#### The number of outliers for the three environmental groups",  "\n"))
      print(xtable(Grouptable), type="html")
      #print(xtable(Grouptable.perc), type="html")
      
      cat("\n", "\n")
      cat(paste ("#### The number of outliers for the three environmental groups scaled by the number of variables in each group",  "\n", "Note that because of the scaling these are not whole numbers."))
      print(xtable(Grouptable.scaled), type="html")
      #print(xtable(Grouptable.scaled.perc), type="html")
    cat("\n")
```


### Proportion of outliers based on different cutoffs
```{r barplot envitable, fig.width=10, fig.height=5, echo=FALSE}
      rownames(envitable.perc) <- env$enviAbb
      dat <- as.matrix(t(envitable.perc[3:ncol(envitable.perc)]))
      dat <- dat[,4:ncol(dat)]
      par(mar=c(6,4,1,1))
      a<- barplot(dat, beside=TRUE,  
                  ylab="Proportion of total outliers",
                  legend.text=names(cos)[which.cutoffs], 
                  ylim=c(0,0.5),
                  xlab="", xaxt="n")

      text(a[4,]+0.5, par("usr")[3]-0.03, 
     srt = 90, adj= 1, xpd = TRUE,
     labels = paste(colnames(dat)), cex=0.8)
```

See the environmentSummary.html for information on the environments and their abbreviations. The x-axis is sorted according to groups.  MAT to EMT is Group 1; MAP to CMD is Group 2, and MWMT to FFP is Group 3.

```{r barplot LLEtable, fig.width=8, fig.height=6, echo=FALSE}
      rownames(LLEtable.perc) <- LLEtable.perc[,1]
      dat <- as.matrix(t(LLEtable.perc[2:ncol(LLEtable.perc)]))
      a<- barplot(dat, beside=TRUE,  
                  ylab="Proportion of total outliers",
                  legend.text=names(cos)[which.cutoffs], 
                  ylim=c(0,1)
                  #xlab="", xaxt="n"
                  )

     # text(a[1,]+0.5, par("usr")[3]-0.03, 
     #srt = 90, adj= 1, xpd = TRUE,
     #labels = paste(colnames(dat)), cex=1)
```

LFMM found a large number of loci with strong associations with Longitude relative to the other variables.  These results differ from the Bayenv2 analysis, which found large number of loci with moderate assocations with longitude, and a smaller number of loci with very strong associations with latitude.  When we look at these results in combination with the Venn diagrams above, we see there is very little overlap among outliers in these three categories.  

```{r barplot grouptable, fig.width=8, fig.height=6, echo=FALSE}
      rownames(Grouptable.perc) <- Grouptable.perc[,1]
      dat <- as.matrix(t(Grouptable.perc[2:ncol(Grouptable.perc)]))
      a<- barplot(dat, beside=TRUE,  
                  ylab="Proportion of total outliers",
                  legend.text=names(cos)[which.cutoffs], 
                  #ylim=c(0,0.2),
                  #xlab="", xaxt="n"
                  )

    #  text(a[1,]+0.5, par("usr")[3]-0.03, 
    # srt = 90, adj= 1, xpd = TRUE,
    # labels = paste(colnames(dat)), cex=1)
```


```{r barplot scaled grouptable, fig.width=8, fig.height=6, echo=FALSE}
      rownames(Grouptable.scaled.perc) <- Grouptable.scaled.perc[,1]
      dat <- as.matrix(t(Grouptable.scaled.perc[2:ncol(Grouptable.scaled.perc)]))
      a<- barplot(dat, beside=TRUE,  
                  ylab="Proportion of total outliers",
                  legend.text=names(cos)[which.cutoffs], 
                  #ylim=c(0,0.2),
                  #xlab="", xaxt="n"
                  )

    #  text(a[1,]+0.5, par("usr")[3]-0.03, 
    # srt = 90, adj= 1, xpd = TRUE,
    # labels = paste(colnames(dat)), cex=1)
```

LFMM found very strong associations with Group 1 relative to the other groups.  Bayenv also found enrichment for strong associations with group 1, but also a large number of loci with moderate assocations with Group 2.  See environmentSummary.html for a summary of the three environmental groups.  

These results can be broken down into the independent environmental variables (graphed above) to see which variables are driving this pattern.  The large z-scores in group 1 are being driven by MAT (mean annual temp), MCMT (mean coldest month), DD_0 (days below 0C), and EMT (extreme minimum temp 30 years) --- so it seems they are being driven by cold (note the exact same results in Bayenv2).  Similar results from Bayenv2 were found for group 2: lfmm found moderate associations with MAP, AHM, and CMD (bayenv found moderate associations with AHM (Annual heat:moisture index), SHM (summer heat:moisture index), EREF (evaporation), and CMD (climate moisture deficit)).  Outliers in Group 3 are from NFFD (number frost-free days) and eFFP (end frost-free period) (same as bayenv2). 

When we look at these results in combination with the Venn diagrams, we can see that there are some overlap among these three groups, except for the most stringent cutoff (I interpret this as evidence of plieotropy (these large-effect loci have effects on traits adapting to multiple, uncorrelated environmental stressors)).  At the most stringent cutoff in the Venn, 90% (compare to 64% from Bayenv2) of loci are associated exclusively with Group 1 (temperature), and the overlapping loci fall into Groups 1 and 3 (temp and frost), or all three groups.

These results seem consistent with the hypothesis that adaptation to temperature is driven mostly by minimum temperatures (but not the length of the freezing period, which is represented by group 3), and consists of relatively fewer loci that (i) may have larger effect sizes and/or (ii) may be acted on by stronger selection.  Adaptation to moisture and precipitation consists of a relatively larger number of loci that (i) may have smaller effect sizes and/or (ii) may be acted on by weaker selection.  These results are also consistent with adaptation to precipitation being associated with more complex traits.

#### Now loop through some these cutoffs and summarize the results for enrichment of different genomic categories:

There are two approaches toward looking at enrichment: based on annotation category, or based on the set of non-coding SNPs used in the covariance matrix.

##### Results based on annotation category

Here, for each locus I used the maximum abs(z_score) observed in any one environment.  Then, I made a new annotation category that lumped together all non-synomymous SNPs. Next, I compared the proportion of SNPs in each annotation category for progressively more stringent cutoffs:


```{r annotation enrichment}
  levels(f2$X.annotation)

### Make a new annotation category
    new.annot <- as.character(unlist(f2$X.annotation))
    new.annot[grep("nonsyn", f2$X.annotation)] <- "nonsyn"
    new.annot <- as.factor(new.annot)
    levels(new.annot)

### Calculate the max(abs(zscore)) for a locus across all environments
  if(!("max.BF" %in% ls())){  #note that this is really calculating z-scores and not BF
    #also note that for NA rows you will get a warning here
  max.BF <- apply(abs(f2[,colBF]), 1, max, na.rm=TRUE)
  max.BF[is.infinite(max.BF)]<-NA
  }
  
### functions to get proportions
get.prop.newannot <- function(V, ind, rowname=NULL){
  a<- tapply(V[ind], new.annot[ind], length)
  a2<- data.frame(t(a/sum(a, na.rm=TRUE)))
  rownames(a2) <- rowname
  a2
  }

### For barplot, x-axis categories are in columns and colored bars are in rows
  enrich.new.annot <- data.frame(cutoff="All", get.prop.newannot(max.BF, TRUE))

  cutoff2 <- as.numeric(cos[1, 4:8])
  cutoff2names <- names(cos[1, 4:8])
  for (i in 1:length(cutoff2)){
    n2 <- data.frame(cutoff=cutoff2names[i], get.prop.newannot(max.BF, max.BF>=cutoff2[i]) )
    print(length(n2))
    enrich.new.annot<- merge(enrich.new.annot, n2, all.x=TRUE, all.y=TRUE)
  }
```


```{r barplot annotation, fig.width=10, fig.height=5, echo=FALSE}
### For barplot, x-axis categories are in columns and colored bars are in rows
      rownames(enrich.new.annot) <- enrich.new.annot[,1]
      dat <- as.matrix(enrich.new.annot[,-1])
      rm <- which(colnames(dat) %in% c("X3primeFLANK", "X5primeFLANK", "HAS_INDEL", "mismatch_altref", "multi.allelic", "unk_adj", "unk_flank"))
      dat <- dat[,-rm]
      par(mar=c(6,4,1,1))
      a<- barplot(dat, beside=TRUE,  
                  ylab="Proportion of total outliers",
                  legend.text=rownames(enrich.new.annot), 
                  ylim=c(0,0.75), xlim=c(0,130),
                  xlab="", xaxt="n",
                  args.legend=list(x=20,y=0.6))

      text(a[4,], par("usr")[3]-0.03, 
     srt = 60, adj= 1, xpd = TRUE,
     labels = paste(colnames(dat)), cex=0.8)
```

The above results are encouraging, but also a bit different from Bayenv2.  With progressively more stringent cutoffs, there is enrichment in unknown open reading frames (bayenv2 found untranslated regions and synonymous SNPs were also enriched up to the highest percentile).  Flanking regions, intronic regions, and regions that are not on transcriptomic contigs all decrease in enrichment with progressively more stringent cutoffs. 

#### Results based on proportion of noncoding SNPs used in covariance matrix
```{r noncoding enrichment}
levels(f2$noncode_in_covar)

get.prop.noncod <- function(V, ind){
  a<- tapply(V[ind], f2$noncode_in_covar[ind], length)
  as.numeric((a/sum(a, na.rm=TRUE))[1])
  }

  enrich.noncod <- get.prop.noncod(max.BF, TRUE)
  for (i in 1:length(cutoff2)){
    enrich.noncod <- c(enrich.noncod, get.prop.noncod(max.BF, max.BF>=cutoff2[i]) )
  }
  names(enrich.noncod) <- c("All", cutoff2names)
  enrich.noncod  
```

The above vector indicates the proportion of outliers for each cutoff that are non-coding loci used in the covariance matrix.  There is a slight increase with each cutoff, but it drops off at the highest percentile.

#### Histogram of BF from noncoding SNPs used in covmat vs. other SNPs
```{r histogram noncoding, fig.height=12}
 low <- min(max.BF, na.rm=TRUE)
 high <- max(max.BF, na.rm=TRUE)
levels(f2$noncode_in_covar)
#[1] "in_covar" "no" 
#note x-axis on histograms are different
  br <- seq(low-0.2, high+0.2, by=0.2)
  par(mfcol=c(3,1), mar=c(4,4,1,1), cex=1.2, las=1)
  hist(max.BF[f2$noncode_in_covar=="no"], breaks=br, freq=FALSE, col="darkgrey", xlim=c(0,15), main="", xlab="Max abs(z-score) across environments")
  hist(max.BF[f2$noncode_in_covar=="in_covar"], breaks=br, freq=FALSE, add=TRUE, col=rgb(0,1,0,0.2))

  hist(max.BF[f2$noncode_in_covar=="no"], breaks=br, xlim=c(5, 15), freq=FALSE, ylim=c(0,0.02),  main="", xlab="Max abs(z-score) across environments", col="darkgrey")
  hist(max.BF[f2$noncode_in_covar=="in_covar"], breaks=br, freq=FALSE, add=TRUE, col=rgb(0,1,0,0.2))

  hist(max.BF[f2$noncode_in_covar=="no"], breaks=br, xlim=c(12, high), freq=FALSE, ylim=c(0,0.001),  main="", xlab="Max abs(z-score) across environments", col="grey")
  hist(max.BF[f2$noncode_in_covar=="in_covar"], breaks=br, freq=FALSE, add=TRUE, col=rgb(0,1,0,0.5))
  legend(16,0.001, c("Noncoding in covmat", "Not in covmat"), fill=c(rgb(0,1,0,0.5),"grey" ), bty="n")
```

The above three plots zoom in on the tail of the abs(z) distribution (remember here that I am plotting the maximum abs(z) observed for a locus across all environments).
Note that the above plots are made with R's *density()* on the y-axis, and this results in densities that are not to scale in the tail - I'll work on that later.  The above results are encouraging.  The coding loci have a longer tail in the BF distribution than the noncoding loci that were used to create the covariance matrix.  Note also that this argument is somewhat circular - maybe by using them to create the covariance matrix, we might over-correct for population structure and so they tend to have low associations.  Nevertheless, this indicates that we may be able to use the non-coding set to create empirical p-values!!!